{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Bag of N-grams**\n",
    "The Bag of N-grams model is an extension of the Bag of Words (BoW) model in natural language processing (NLP). While the traditional Bag of Words model represents a document as an unordered set of words and their frequencies, the Bag of N-grams model considers sequences of consecutive words, known as n-grams, in addition to individual words.\n",
    "\n",
    "- Document 1: \"The cat in the hat.\"\n",
    "- Document 2: \"The cat sat on the mat.\"\n",
    "\n",
    "Vocabulary: {The cat, cat in, in the, the hat, hat sat, sat on, on the, the mat}\n",
    "\n",
    "Vector representation:\n",
    "- Document 1: [1, 1, 1, 1, 0, 0, 0, 0]\n",
    "- Document 2: [1, 0, 0, 0, 1, 1, 1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import pprint\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding how to generate n-grams using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loki': 3, 'is': 2, 'an': 1, 'amazing': 0, 'movie': 4}\n"
     ]
    }
   ],
   "source": [
    "# BoW model\n",
    "cv = CountVectorizer()\n",
    "cv.fit(['Loki is an amazing movie.'])\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amazing': 0,\n",
      " 'amazing movie': 1,\n",
      " 'an': 2,\n",
      " 'an amazing': 3,\n",
      " 'an amazing movie': 4,\n",
      " 'is': 5,\n",
      " 'is an': 6,\n",
      " 'is an amazing': 7,\n",
      " 'loki': 8,\n",
      " 'loki is': 9,\n",
      " 'loki is an': 10,\n",
      " 'movie': 11}\n"
     ]
    }
   ],
   "source": [
    "# n-gram model\n",
    "cv = CountVectorizer(ngram_range=(1,3))\n",
    "cv.fit(['Loki is an amazing movie.'])\n",
    "pprint.pprint(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to another example\n",
    "corpus = [\n",
    "    \"Thor ate pizza\",\n",
    "    \"Loki is tall\",\n",
    "    \"Loki is eating pizza\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will preprocess the corpus first (sw and lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(nltk.corpus.stopwords.words('english'))\n",
    "lemma = nltk.stem.WordNetLemmatizer()\n",
    "clear_corpus = []\n",
    "for sentence in corpus:\n",
    "    word = nltk.word_tokenize(sentence)\n",
    "    word = [lemma.lemmatize(w) for w in word if w not in sw]\n",
    "    clear_corpus.append(\" \".join(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thor ate pizza', 'Loki is tall', 'Loki is eating pizza']\n",
      "\n",
      " ['Thor ate pizza', 'Loki tall', 'Loki eating pizza']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)\n",
    "print(\"\\n\",clear_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ate': 0,\n",
      " 'ate pizza': 1,\n",
      " 'eating': 2,\n",
      " 'eating pizza': 3,\n",
      " 'loki': 4,\n",
      " 'loki eating': 5,\n",
      " 'loki tall': 6,\n",
      " 'pizza': 7,\n",
      " 'tall': 8,\n",
      " 'thor': 9,\n",
      " 'thor ate': 10}\n"
     ]
    }
   ],
   "source": [
    "# n-gram model\n",
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "cv.fit(clear_corpus)\n",
    "pprint.pprint(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(['Thor ate pizza']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(['Hulk ate pizza']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **News Category Classification using Bag of n-gram**\n",
    "\n",
    "This dataset contains around 210k news headlines from 2012 to 2022 from HuffPost. This is one of the biggest news datasets and can serve as a benchmark for a variety of computational linguistic tasks. \n",
    "Each record in the dataset consists of the following attributes:\n",
    "\n",
    "- category: category in which the article was published.\n",
    "- headline: the headline of the news article.\n",
    "- authors: list of authors who contributed to the article.\n",
    "- link: link to the original news article.\n",
    "- short_description: Abstract of the news article.\n",
    "- date: publication date of the article.\n",
    "\n",
    "Dataset = https://www.kaggle.com/datasets/rmisra/news-category-dataset\n",
    "- Category can be one of these 4: 'BUSINESS', 'SPORTS', 'CRIME', 'SCIENCE', to keep things simple the data trimmed so it different than original kaggel dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Watching Schrödinger's Cat Die University of C...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WATCH: Freaky Vortex Opens Up In Flooded Lake</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entrepreneurs Today Don't Need a Big Budget to...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These Roads Could Recharge Your Electric Car A...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Civilian 'Guard' Fires Gun While 'Protecting' ...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  Watching Schrödinger's Cat Die University of C...   SCIENCE\n",
       "1     WATCH: Freaky Vortex Opens Up In Flooded Lake    SCIENCE\n",
       "2  Entrepreneurs Today Don't Need a Big Budget to...  BUSINESS\n",
       "3  These Roads Could Recharge Your Electric Car A...  BUSINESS\n",
       "4  Civilian 'Guard' Fires Gun While 'Protecting' ...     CRIME"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data\\\\news_dataset.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BUSINESS    4254\n",
       "SPORTS      4167\n",
       "CRIME       2893\n",
       "SCIENCE     1381\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 1381\n",
    "\n",
    "df_business = df[df['category'] == 'BUSINESS'].sample(min_samples,random_state=42)\n",
    "df_sport = df[df['category'] == 'SPORTS'].sample(min_samples,random_state=42)\n",
    "df_crime = df[df['category'] == 'CRIME'].sample(min_samples,random_state=42)\n",
    "df_science = df[df['category'] == 'SCIENCE'].sample(min_samples,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BUSINESS    1381\n",
       "SPORTS      1381\n",
       "CRIME       1381\n",
       "SCIENCE     1381\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balance = pd.concat([df_business,df_sport,df_crime,df_science], axis = 0).reset_index(drop=True)\n",
    "df_balance['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert category into number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Develop the Next Generation of Innovato...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Madoff Victims' Payout Nears $7.2 Billion, Tru...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bay Area Floats 'Sanctuary In Transit Policy' ...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microsoft Agrees To Acquire LinkedIn For $26.2...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inside A Legal, Multibillion Dollar Weed Market</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  category_num\n",
       "0  How to Develop the Next Generation of Innovato...  BUSINESS             0\n",
       "1  Madoff Victims' Payout Nears $7.2 Billion, Tru...  BUSINESS             0\n",
       "2  Bay Area Floats 'Sanctuary In Transit Policy' ...  BUSINESS             0\n",
       "3  Microsoft Agrees To Acquire LinkedIn For $26.2...  BUSINESS             0\n",
       "4   Inside A Legal, Multibillion Dollar Weed Market   BUSINESS             0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balance['category_num'] = df_balance['category'].map({'BUSINESS': 0, 'SPORTS': 1, 'CRIME': 2, 'SCIENCE': 3})\n",
    "df_balance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build a model with original text (no pre processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4419,),\n",
       " (1105,),\n",
       " 0    1105\n",
       " 3    1105\n",
       " 1    1105\n",
       " 2    1104\n",
       " Name: category_num, dtype: int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_balance['text'], \n",
    "                                                    df_balance['category_num'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=df_balance['category_num']\n",
    "                                                    )\n",
    "X_train.shape, X_test.shape, y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train and evaluate a model on basic bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84       276\n",
      "           1       0.92      0.85      0.88       276\n",
      "           2       0.91      0.89      0.90       277\n",
      "           3       0.89      0.82      0.85       276\n",
      "\n",
      "    accuracy                           0.87      1105\n",
      "   macro avg       0.88      0.87      0.87      1105\n",
      "weighted avg       0.88      0.87      0.87      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vecotrizer_bow', CountVectorizer()),\n",
    "    ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train and evaluate on ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.95      0.81       276\n",
      "           1       0.92      0.80      0.85       276\n",
      "           2       0.91      0.88      0.89       277\n",
      "           3       0.92      0.77      0.84       276\n",
      "\n",
      "    accuracy                           0.85      1105\n",
      "   macro avg       0.86      0.85      0.85      1105\n",
      "weighted avg       0.86      0.85      0.85      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vecotrizer_ngram', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build a model with text pre-processing to remove stop words, punctuations and apply lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hulk eat pizza'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining preprocessing function\n",
    "def preproces_senteces(sentence):\n",
    "    sw = set(nltk.corpus.stopwords.words('english'))\n",
    "    lemma = nltk.stem.WordNetLemmatizer()\n",
    "    word = nltk.word_tokenize(sentence)\n",
    "    word = [lemma.lemmatize(w, pos= 'v') for w in word if w not in sw]\n",
    "    return \" \".join(word)\n",
    "preproces_senteces('Hulk is eating pizza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balance['preprocess_text'] = df_balance['text'].apply(preproces_senteces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_num</th>\n",
       "      <th>preprocess_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Develop the Next Generation of Innovato...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>How Develop Next Generation Innovators : Stop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Madoff Victims' Payout Nears $7.2 Billion, Tru...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Madoff Victims ' Payout Nears $ 7.2 Billion , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bay Area Floats 'Sanctuary In Transit Policy' ...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Bay Area Floats 'Sanctuary In Transit Policy '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microsoft Agrees To Acquire LinkedIn For $26.2...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Microsoft Agrees To Acquire LinkedIn For $ 26....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inside A Legal, Multibillion Dollar Weed Market</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Inside A Legal , Multibillion Dollar Weed Market</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  category_num  \\\n",
       "0  How to Develop the Next Generation of Innovato...  BUSINESS             0   \n",
       "1  Madoff Victims' Payout Nears $7.2 Billion, Tru...  BUSINESS             0   \n",
       "2  Bay Area Floats 'Sanctuary In Transit Policy' ...  BUSINESS             0   \n",
       "3  Microsoft Agrees To Acquire LinkedIn For $26.2...  BUSINESS             0   \n",
       "4   Inside A Legal, Multibillion Dollar Weed Market   BUSINESS             0   \n",
       "\n",
       "                                     preprocess_text  \n",
       "0  How Develop Next Generation Innovators : Stop ...  \n",
       "1  Madoff Victims ' Payout Nears $ 7.2 Billion , ...  \n",
       "2  Bay Area Floats 'Sanctuary In Transit Policy '...  \n",
       "3  Microsoft Agrees To Acquire LinkedIn For $ 26....  \n",
       "4   Inside A Legal , Multibillion Dollar Weed Market  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4419,),\n",
       " (1105,),\n",
       " 0    1105\n",
       " 3    1105\n",
       " 1    1105\n",
       " 2    1104\n",
       " Name: category_num, dtype: int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_balance['preprocess_text'], \n",
    "                                                    df_balance['category_num'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=df_balance['category_num']\n",
    "                                                    )\n",
    "X_train.shape, X_test.shape, y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train and evaluate a model on basic bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       276\n",
      "           1       0.88      0.87      0.87       276\n",
      "           2       0.90      0.92      0.91       277\n",
      "           3       0.89      0.84      0.86       276\n",
      "\n",
      "    accuracy                           0.88      1105\n",
      "   macro avg       0.88      0.88      0.88      1105\n",
      "weighted avg       0.88      0.88      0.88      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vecotrizer_bow', CountVectorizer()),\n",
    "    ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train and evaluate on ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       276\n",
      "           1       0.90      0.87      0.88       276\n",
      "           2       0.91      0.90      0.90       277\n",
      "           3       0.88      0.83      0.86       276\n",
      "\n",
      "    accuracy                           0.88      1105\n",
      "   macro avg       0.88      0.88      0.88      1105\n",
      "weighted avg       0.88      0.88      0.88      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vecotrizer_ngram', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test,clf.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
