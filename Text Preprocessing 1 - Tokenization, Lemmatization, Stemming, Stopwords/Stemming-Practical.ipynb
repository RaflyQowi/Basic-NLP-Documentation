{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stemming**\n",
    "Stemming is a text normalization process in natural language processing (NLP) that involves reducing words to their base or root form, known as the \"stem.\" The purpose of stemming is to simplify words and group together different inflections or derivations of the same word so that they can be treated as a single entity.\n",
    "\n",
    "For example, consider the words \"running,\" \"ran,\" and \"runner.\" The stem of these words is \"run.\" Stemming would transform all these words into the common base form:\n",
    "\n",
    "- running -> run\n",
    "- ran -> run\n",
    "- runner -> run\n",
    "\n",
    "The idea is to eliminate variations in word forms so that similar words are treated as equivalent during text analysis, retrieval, or other NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PorterStemmer\n",
    "The Porter stemming algorithm is a process for removing suffixes from words in English. Removing suffixes. automatically is an operation which is especially useful in the field of information retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. eating --> eat\n",
      "2. eats --> eat\n",
      "3. eaten --> eaten\n",
      "4. writing --> write\n",
      "5. writes --> write\n",
      "6. programming --> program\n",
      "7. programs --> program\n",
      "8. history --> histori\n",
      "9. finally --> final\n",
      "10. finalized --> final\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(words):\n",
    "    print(f\"{i+1}. {word} --> {porter_stem.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegexpStemmer class\n",
    "A stemmer that uses regular expressions to identify morphological affixes. Any substrings that match the regular expressions will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. eating --> eat\n",
      "2. eats --> eat\n",
      "3. eaten --> eaten\n",
      "4. writing --> writ\n",
      "5. writes --> write\n",
      "6. programming --> programm\n",
      "7. programs --> program\n",
      "8. history --> history\n",
      "9. finally --> finally\n",
      "10. finalized --> finalized\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(words):\n",
    "    print(f\"{i+1}. {word} --> {reg_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowball Stemmer\n",
    "Snowball Stemmer is also known as the Porter2 stemming algorithm because it is a better version of the Porter Stemmer. It is more aggressive than Porter Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. eating --> eat\n",
      "2. eats --> eat\n",
      "3. eaten --> eaten\n",
      "4. writing --> write\n",
      "5. writes --> write\n",
      "6. programming --> program\n",
      "7. programs --> program\n",
      "8. history --> histori\n",
      "9. finally --> final\n",
      "10. finalized --> final\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(words):\n",
    "    print(f\"{i+1}. {word} --> {sn_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snowball vs porter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'fair')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stem.stem(\"fairly\"), sn_stemmer.stem(\"fairly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sportingli', 'sport')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stem.stem(\"sportingly\"), sn_stemmer.stem(\"sportingly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
